#require __LANGUAGE_NAME__ == slu4-min64x4-asm
#require __LANGUAGE_VERSION__ >= 1.1.0
#create-scope "mathlib64" prefix="ml64_"
#create-scope "mathlib64_internal" prefix="_"

.memzone ZERO_PAGE_LIBS
#mute
; 64-bit multiplication variables
_mul64_op1:           .8byte 0    ; First operand (multiplicand)
_mul64_op2:           .8byte 0    ; Second operand (multiplier)
_mul64_result:        .16byte 0   ; 128-bit result
_mul64_p:             .8byte 0    ; 64-bit temporary product
_mul64_sumA_carry:    .byte 0     ; carry-out of A0 + A1
_mul64_sumB_carry:    .byte 0     ; carry-out of B0 + B1
_mul32_sumA_carry:    .byte 0     ; carry-out of a0 + a1 (32-bit core)
_mul32_sumB_carry:    .byte 0     ; carry-out of b0 + b1 (32-bit core)
_mul64_p_hi:          .byte 0     ; extra bits above 64 for Karatsuba Z1
_mul64_sign_flag:     .byte 0     ; sign flag for signed multiplication
_mul16_op1:           .2byte 0
_mul16_op2:           .2byte 0
_mul16_op2_saved:     .2byte 0
_mul16_result:        .4byte 0
_mul16_multiplicand:  .4byte 0
_mul16_counter:       .byte 0

#ifdef USE_ACCELERATOR
#ifndef MULTIPLIER_A
; Hardware multiplier accelerator memory-mapped registers
MULTIPLIER_A = $FED0
MULTIPLIER_B = $FED1
MULTIPLIER_RESULT_LSB = $FED2
MULTIPLIER_RESULT_MSB = $FED3
#endif
#endif

#emit

.memzone USER_APPS
.align

; Negates a 64-bit number in place (2's complement)
; Expects the number in _mul64_op1
_negate64_op1:
    NOQ _mul64_op1
    NOQ _mul64_op1+4
    INZ _mul64_op1+0
    FCC .neg_done
    INZ _mul64_op1+1
    FCC .neg_done
    INZ _mul64_op1+2
    FCC .neg_done
    INZ _mul64_op1+3
    FCC .neg_done
    INZ _mul64_op1+4
    FCC .neg_done
    INZ _mul64_op1+5
    FCC .neg_done
    INZ _mul64_op1+6
    FCC .neg_done
    INZ _mul64_op1+7
.neg_done:
    RTS

; Negates a 64-bit number in place (2's complement)
; Expects the number in _mul64_op2
_negate64_op2:
    NOQ _mul64_op2
    NOQ _mul64_op2+4
    INZ _mul64_op2+0
    FCC .neg_done
    INZ _mul64_op2+1
    FCC .neg_done
    INZ _mul64_op2+2
    FCC .neg_done
    INZ _mul64_op2+3
    FCC .neg_done
    INZ _mul64_op2+4
    FCC .neg_done
    INZ _mul64_op2+5
    FCC .neg_done
    INZ _mul64_op2+6
    FCC .neg_done
    INZ _mul64_op2+7
.neg_done:
    RTS

; Negates a 128-bit number in place (2's complement)
; Expects the number in _mul64_result
_negate128:
    NOQ _mul64_result
    NOQ _mul64_result+4
    NOQ _mul64_result+8
    NOQ _mul64_result+12
    INZ _mul64_result+0
    FCC .neg128_done
    INZ _mul64_result+1
    FCC .neg128_done
    INZ _mul64_result+2
    FCC .neg128_done
    INZ _mul64_result+3
    FCC .neg128_done
    INZ _mul64_result+4
    FCC .neg128_done
    INZ _mul64_result+5
    FCC .neg128_done
    INZ _mul64_result+6
    FCC .neg128_done
    INZ _mul64_result+7
    FCC .neg128_done
    INZ _mul64_result+8
    FCC .neg128_done
    INZ _mul64_result+9
    FCC .neg128_done
    INZ _mul64_result+10
    FCC .neg128_done
    INZ _mul64_result+11
    FCC .neg128_done
    INZ _mul64_result+12
    FCC .neg128_done
    INZ _mul64_result+13
    FCC .neg128_done
    INZ _mul64_result+14
    FCC .neg128_done
    INZ _mul64_result+15
.neg128_done:
    RTS

#ifdef USE_ACCELERATOR
#print magenta "Compiling hardware accelerated 16-bit multiplication"

_multiplication16_core:
    MZB _mul16_op1+0,MULTIPLIER_A
    MZB _mul16_op2+0,MULTIPLIER_B

    ; Read 16-bit result from hardware into low word of final result
    MBZ MULTIPLIER_RESULT_LSB,_mul16_result+0
    MBZ MULTIPLIER_RESULT_MSB,_mul16_result+1

    ; Perform A_high × B_high (contributes to result bits 16-31)
    MZB _mul16_op1+1,MULTIPLIER_A
    MZB _mul16_op2+1,MULTIPLIER_B

    ; Read 16-bit result from hardware in high word of final result
    MBZ MULTIPLIER_RESULT_LSB,_mul16_result+2
    MBZ MULTIPLIER_RESULT_MSB,_mul16_result+3

    ; Perform A_high × B_low (contributes to result bits 8-23)
    MZB _mul16_op1+1,MULTIPLIER_A
    MZB _mul16_op2+0,MULTIPLIER_B

    ; Add 16-bit result directly to _mul16_result at byte offset 1
    LDB MULTIPLIER_RESULT_LSB
    AD.Z _mul16_result+1
    LDB MULTIPLIER_RESULT_MSB
    AC.Z _mul16_result+2
    LDI 0
    AC.Z _mul16_result+3

    ; Perform A_low × B_high (contributes to result bits 8-23)
    MZB _mul16_op1+0,MULTIPLIER_A
    MZB _mul16_op2+1,MULTIPLIER_B

    ; Add 16-bit result directly to _mul16_result at byte offset 1
    LDB MULTIPLIER_RESULT_LSB
    AD.Z _mul16_result+1
    LDB MULTIPLIER_RESULT_MSB
    AC.Z _mul16_result+2
    LDI 0
    AC.Z _mul16_result+3

    RTS

#else
#print yellow "Compiling software-only 16-bit multiplication"

.align
_multiplication16_core:
    CLQ _mul16_result

    CLQ _mul16_multiplicand
    LDZ _mul16_op1+0
    STZ _mul16_multiplicand+0
    LDZ _mul16_op1+1
    STZ _mul16_multiplicand+1

    ; Initialize counter - optimize for 8-bit vs 16-bit multiplier
    CIZ 0,_mul16_op2+1
    FNE .use_16_iterations
    MIZ 8,_mul16_counter
    FPA .mul_loop
.use_16_iterations:
    MIZ 16,_mul16_counter

.mul_loop:
    ; Check if LSB of multiplier is set
    LDZ _mul16_op2
    ANI 1
    CPI 1
    FNE .mul_skip_add

    ; Add 32-bit multiplicand to 32-bit result with carry propagation
    AQQ _mul16_multiplicand,_mul16_result

.mul_skip_add:
    ; Shift 32-bit multiplicand left (multiply by 2)
    LLQ _mul16_multiplicand

    ; Shift multiplier right (divide by 2)
    CLC
    RRZ _mul16_op2+1
    RRZ _mul16_op2

    ; Decrement counter and continue if not zero
    DEZ _mul16_counter
    FNE .mul_loop

    RTS

#endif

; _multiplication32_core
; 32x32 Karatsuba multiply using 16-bit core.
; Inputs: _mul64_op1 (low 4 bytes), _mul64_op2 (low 4 bytes)
; Output: _mul64_p (64-bit)
.align
_multiplication32_core:
    ; Z0
    MVV _mul64_op1+0,_mul16_op1
    MVV _mul64_op2+0,_mul16_op2
    JPS _multiplication16_core
    MQQ _mul16_result,_mul64_p+0

    ; Z2
    MVV _mul64_op1+2,_mul16_op1
    MVV _mul64_op2+2,_mul16_op2
    JPS _multiplication16_core
    MQQ _mul16_result,_mul64_p+4

    ; Z1 (carry-corrected Karatsuba)
    ; sumA = a0 + a1, sumB = b0 + b1
    CLZ _mul32_sumA_carry
    MVV _mul64_op1+0,_mul16_op1
    AVV _mul64_op1+2,_mul16_op1
    FCC .no_carry_a
    INZ _mul32_sumA_carry
.no_carry_a:

    CLZ _mul32_sumB_carry
    MVV _mul64_op2+0,_mul16_op2
    AVV _mul64_op2+2,_mul16_op2
    FCC .no_carry_b
    INZ _mul32_sumB_carry
.no_carry_b:

    MVV _mul16_op2,_mul16_op2_saved
    JPS _multiplication16_core

    CLZ _mul64_p_hi

    ; if sumA_carry: add sumB_lo << 16 to P
    CIZ 0,_mul32_sumA_carry
    FEQ .skip_add_b
    AVV _mul16_op2_saved,_mul16_result+2
    FCC .no_pcarry1
    INZ _mul64_p_hi
.no_pcarry1:
.skip_add_b:

    ; if sumB_carry: add sumA_lo << 16 to P
    CIZ 0,_mul32_sumB_carry
    FEQ .skip_add_a
    AVV _mul16_op1,_mul16_result+2
    FCC .no_pcarry2
    INZ _mul64_p_hi
.no_pcarry2:
.skip_add_a:

    ; if sumA_carry & sumB_carry: add 1<<32
    CIZ 0,_mul32_sumA_carry
    FEQ .skip_ab
    CIZ 0,_mul32_sumB_carry
    FEQ .skip_ab
    INZ _mul64_p_hi
.skip_ab:

    ; Z1 = P - Z0 - Z2 (adjust p_hi for borrows)
    SQQ _mul64_p+0,_mul16_result
    FCC .borrow0
    FPA .no_borrow0
.borrow0:
    DEZ _mul64_p_hi
.no_borrow0:
    SQQ _mul64_p+4,_mul16_result
    FCC .borrow1
    FPA .no_borrow1
.borrow1:
    DEZ _mul64_p_hi
.no_borrow1:

    ; add it in (Z1 << 16)
    AQQ _mul16_result,_mul64_p+2
    LDZ _mul64_p_hi
    AC.Z _mul64_p+6
    LDI 0
    AC.Z _mul64_p+7

    RTS

; _multiplication64_karatsuba_core
; 64-bit multiply using Karatsuba (3x 32-bit products).
.align
_multiplication64_karatsuba_core:
    ; Z0 = A0 * B0
    JPS _multiplication32_core
    MQQ _mul64_p,_mul64_result+0
    MQQ _mul64_p+4,_mul64_result+4

    ; Save A0/B0 while computing Z2
    MQQ _mul64_op1+0,_mul64_result+8
    MQQ _mul64_op2+0,_mul64_result+12

    ; Z2 = A1 * B1
    MQQ _mul64_op1+4,_mul64_op1+0
    MQQ _mul64_op2+4,_mul64_op2+0
    JPS _multiplication32_core

    ; Restore A0/B0 and store Z2
    MQQ _mul64_result+8,_mul64_op1+0
    MQQ _mul64_result+12,_mul64_op2+0
    MQQ _mul64_p,_mul64_result+8
    MQQ _mul64_p+4,_mul64_result+12

    ; sumA = A0 + A1
    CLZ _mul64_sumA_carry
    LDZ _mul64_op1+4
    AD.Z _mul64_op1+0
    LDZ _mul64_op1+5
    AC.Z _mul64_op1+1
    LDZ _mul64_op1+6
    AC.Z _mul64_op1+2
    LDZ _mul64_op1+7
    AC.Z _mul64_op1+3
    BCC .no_carry_a
    INZ _mul64_sumA_carry
.no_carry_a:

    ; sumB = B0 + B1
    CLZ _mul64_sumB_carry
    LDZ _mul64_op2+4
    AD.Z _mul64_op2+0
    LDZ _mul64_op2+5
    AC.Z _mul64_op2+1
    LDZ _mul64_op2+6
    AC.Z _mul64_op2+2
    LDZ _mul64_op2+7
    AC.Z _mul64_op2+3
    BCC .no_carry_b
    INZ _mul64_sumB_carry
.no_carry_b:

    ; P = sumA * sumB
    JPS _multiplication32_core

    CLZ _mul64_p_hi

    ; if sumA_carry: add sumB << 32 to P
    CIZ 0,_mul64_sumA_carry
    BEQ .skip_add_b
    LDZ _mul64_op2+0
    AD.Z _mul64_p+4
    LDZ _mul64_op2+1
    AC.Z _mul64_p+5
    LDZ _mul64_op2+2
    AC.Z _mul64_p+6
    LDZ _mul64_op2+3
    AC.Z _mul64_p+7
    BCC .no_pcarry1
    INZ _mul64_p_hi
.no_pcarry1:
.skip_add_b:

    ; if sumB_carry: add sumA << 32 to P
    CIZ 0,_mul64_sumB_carry
    BEQ .skip_add_a
    LDZ _mul64_op1+0
    AD.Z _mul64_p+4
    LDZ _mul64_op1+1
    AC.Z _mul64_p+5
    LDZ _mul64_op1+2
    AC.Z _mul64_p+6
    LDZ _mul64_op1+3
    AC.Z _mul64_p+7
    BCC .no_pcarry2
    INZ _mul64_p_hi
.no_pcarry2:
.skip_add_a:

    ; if sumA_carry & sumB_carry: add 1<<64
    CIZ 0,_mul64_sumA_carry
    BEQ .skip_ab
    CIZ 0,_mul64_sumB_carry
    BEQ .skip_ab
    INZ _mul64_p_hi
.skip_ab:

    ; P = P - Z0 (adjust p_hi for borrows)
    LDZ _mul64_result+0
    SU.Z _mul64_p+0
    LDZ _mul64_result+1
    SC.Z _mul64_p+1
    LDZ _mul64_result+2
    SC.Z _mul64_p+2
    LDZ _mul64_result+3
    SC.Z _mul64_p+3
    LDZ _mul64_result+4
    SC.Z _mul64_p+4
    LDZ _mul64_result+5
    SC.Z _mul64_p+5
    LDZ _mul64_result+6
    SC.Z _mul64_p+6
    LDZ _mul64_result+7
    SC.Z _mul64_p+7
    BCS .no_borrow0
.borrow0:
    DEZ _mul64_p_hi
.no_borrow0:

    ; P = P - Z2 (adjust p_hi for borrows)
    LDZ _mul64_result+8
    SU.Z _mul64_p+0
    LDZ _mul64_result+9
    SC.Z _mul64_p+1
    LDZ _mul64_result+10
    SC.Z _mul64_p+2
    LDZ _mul64_result+11
    SC.Z _mul64_p+3
    LDZ _mul64_result+12
    SC.Z _mul64_p+4
    LDZ _mul64_result+13
    SC.Z _mul64_p+5
    LDZ _mul64_result+14
    SC.Z _mul64_p+6
    LDZ _mul64_result+15
    SC.Z _mul64_p+7
    BCS .no_borrow1
.borrow1:
    DEZ _mul64_p_hi
.no_borrow1:

    ; add Z1 (P << 32)
    LDZ _mul64_p+0
    AD.Z _mul64_result+4
    LDZ _mul64_p+1
    AC.Z _mul64_result+5
    LDZ _mul64_p+2
    AC.Z _mul64_result+6
    LDZ _mul64_p+3
    AC.Z _mul64_result+7
    LDZ _mul64_p+4
    AC.Z _mul64_result+8
    LDZ _mul64_p+5
    AC.Z _mul64_result+9
    LDZ _mul64_p+6
    AC.Z _mul64_result+10
    LDZ _mul64_p+7
    AC.Z _mul64_result+11
    LDI 0
    AC.Z _mul64_result+12
    LDI 0
    AC.Z _mul64_result+13
    LDI 0
    AC.Z _mul64_result+14
    LDI 0
    AC.Z _mul64_result+15

    ; add p_hi (extra Z1 bits above 64)
    CLC
    LDZ _mul64_p_hi
    AD.Z _mul64_result+12
    LDI 0
    AC.Z _mul64_result+13
    LDI 0
    AC.Z _mul64_result+14
    LDI 0
    AC.Z _mul64_result+15

    RTS

; ml64_unsigned_multiply
; Multiplies two unsigned 64-bit integers (Karatsuba). Result is 128-bit.
; Stack: SP+3..10=multiplier, SP+11..18=multiplicand (MSB at lower address)
; Result overwrites both inputs on the stack.
ml64_unsigned_multiply:
    ; Copy multiplicand from stack to _mul64_op1
    LDS 18
    STZ _mul64_op1+0
    LDS 17
    STZ _mul64_op1+1
    LDS 16
    STZ _mul64_op1+2
    LDS 15
    STZ _mul64_op1+3
    LDS 14
    STZ _mul64_op1+4
    LDS 13
    STZ _mul64_op1+5
    LDS 12
    STZ _mul64_op1+6
    LDS 11
    STZ _mul64_op1+7

    ; Copy multiplier from stack to _mul64_op2
    LDS 10
    STZ _mul64_op2+0
    LDS 9
    STZ _mul64_op2+1
    LDS 8
    STZ _mul64_op2+2
    LDS 7
    STZ _mul64_op2+3
    LDS 6
    STZ _mul64_op2+4
    LDS 5
    STZ _mul64_op2+5
    LDS 4
    STZ _mul64_op2+6
    LDS 3
    STZ _mul64_op2+7

    JPS _multiplication64_karatsuba_core

    ; Copy 128-bit result back to stack
    LDZ _mul64_result+15
    STS 3
    LDZ _mul64_result+14
    STS 4
    LDZ _mul64_result+13
    STS 5
    LDZ _mul64_result+12
    STS 6
    LDZ _mul64_result+11
    STS 7
    LDZ _mul64_result+10
    STS 8
    LDZ _mul64_result+9
    STS 9
    LDZ _mul64_result+8
    STS 10
    LDZ _mul64_result+7
    STS 11
    LDZ _mul64_result+6
    STS 12
    LDZ _mul64_result+5
    STS 13
    LDZ _mul64_result+4
    STS 14
    LDZ _mul64_result+3
    STS 15
    LDZ _mul64_result+2
    STS 16
    LDZ _mul64_result+1
    STS 17
    LDZ _mul64_result+0
    STS 18

    RTS

; ml64_signed_multiply
; Multiplies two signed 64-bit integers (Karatsuba). Result is 128-bit.
ml64_signed_multiply:
    ; Copy multiplicand from stack to _mul64_op1
    LDS 18
    STZ _mul64_op1+0
    LDS 17
    STZ _mul64_op1+1
    LDS 16
    STZ _mul64_op1+2
    LDS 15
    STZ _mul64_op1+3
    LDS 14
    STZ _mul64_op1+4
    LDS 13
    STZ _mul64_op1+5
    LDS 12
    STZ _mul64_op1+6
    LDS 11
    STZ _mul64_op1+7

    CLZ _mul64_sign_flag

    ; Check sign of first operand
    LDZ _mul64_op1+7
    ANI $80
    FEQ .check_second_sign
    INZ _mul64_sign_flag
    JPS _negate64_op1

.check_second_sign:
    ; Copy multiplier from stack to _mul64_op2
    LDS 10
    STZ _mul64_op2+0
    LDS 9
    STZ _mul64_op2+1
    LDS 8
    STZ _mul64_op2+2
    LDS 7
    STZ _mul64_op2+3
    LDS 6
    STZ _mul64_op2+4
    LDS 5
    STZ _mul64_op2+5
    LDS 4
    STZ _mul64_op2+6
    LDS 3
    STZ _mul64_op2+7

    ; Check sign of second operand
    LDZ _mul64_op2+7
    ANI $80
    FEQ .do_multiply
    LDI 1
    XR.Z _mul64_sign_flag
    JPS _negate64_op2

.do_multiply:
    JPS _multiplication64_karatsuba_core

    CIZ 0,_mul64_sign_flag
    FEQ .return_result
    JPS _negate128

.return_result:
    ; Copy 128-bit result back to stack
    LDZ _mul64_result+15
    STS 3
    LDZ _mul64_result+14
    STS 4
    LDZ _mul64_result+13
    STS 5
    LDZ _mul64_result+12
    STS 6
    LDZ _mul64_result+11
    STS 7
    LDZ _mul64_result+10
    STS 8
    LDZ _mul64_result+9
    STS 9
    LDZ _mul64_result+8
    STS 10
    LDZ _mul64_result+7
    STS 11
    LDZ _mul64_result+6
    STS 12
    LDZ _mul64_result+5
    STS 13
    LDZ _mul64_result+4
    STS 14
    LDZ _mul64_result+3
    STS 15
    LDZ _mul64_result+2
    STS 16
    LDZ _mul64_result+1
    STS 17
    LDZ _mul64_result+0
    STS 18

    RTS
